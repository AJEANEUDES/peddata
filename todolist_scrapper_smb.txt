# üèÅ Scraping des donn√©es de Super Mario Bros. sur Speedrun.com

## Objectif

Collecter de fa√ßon structur√©e les donn√©es cl√©s de la page Super Mario Bros. sur [Speedrun.com](https://www.speedrun.com/smb1) pour permettre une analyse comparative de la difficult√© du jeu et des performances des joueurs.

---

## Donn√©es √† extraire

### 1. Leaderboards (Classements)
- **Cat√©gorie** (ex: Any%, Warpless, etc.)
- **Rang**
- **Nom du joueur**
- **Temps r√©alis√©**
- **Date**
- **Plateforme**

### 2. Guides (important)
- **Titre du guide**
- **Auteur**
- **Date de publication**
- **Lien vers le guide**

### 3. Ressources
- **Nom de la ressource**
- **Type** (outil, script, patch, etc.)
- **Auteur**
- **Date de publication**
- **Lien de t√©l√©chargement**

### 4. Forums
- **Titre du fil de discussion**
- **Auteur**
- **Date de la derni√®re activit√©**
- **Nombre de r√©ponses**

### 5. Statistiques g√©n√©rales
- **Nombre de followers**
- **Nombre total de runs**
- **Nombre de joueurs**

---

## Technologies recommand√©es

- **Langage :** Python
- **Librairies :**
  - `requests` ‚Äì Requ√™tes HTTP
  - `BeautifulSoup` ‚Äì Analyse HTML
  - `pandas` ‚Äì Structuration et analyse des donn√©es

---

## Consid√©rations √©thiques et techniques

- **Respectez les [conditions d‚Äôutilisation de Speedrun.com](https://www.speedrun.com/terms).**
- **Impl√©mentez des d√©lais (`time.sleep`) entre les requ√™tes** pour ne pas surcharger le serveur.
- **Pr√©voyez la gestion des erreurs** (HTTP, parsing, changement de structure HTML).

---

## Exemple de structure de script Python

```python
import requests
from bs4 import BeautifulSoup
import pandas as pd
import time

BASE_URL = "https://www.speedrun.com/smb1"

headers = {
    "User-Agent": "Mozilla/5.0 (compatible; scraping for research; +https://github.com/...)"
}

def get_soup(url):
    resp = requests.get(url, headers=headers)
    resp.raise_for_status()
    return BeautifulSoup(resp.text, "html.parser")

# TODO: Fonctions pour extraire chaque section :
# - extract_leaderboards(soup)
# - extract_guides(soup)
# - extract_resources(soup)
# - extract_forums(soup)
# - extract_stats(soup)

def main():
    soup = get_soup(BASE_URL)
    # Extraction des donn√©es
    # leaderboards = extract_leaderboards(soup)
    # guides = extract_guides(soup)
    # resources = extract_resources(soup)
    # forums = extract_forums(soup)
    # stats = extract_stats(soup)
    # Sauvegarde ou analyse avec pandas

if __name__ == "__main__":
    main()
```

---

## Conseils pour le scraping

- Inspectez le HTML pour trouver les s√©lecteurs CSS pr√©cis de chaque section.
- Les leaderboards peuvent n√©cessiter la navigation dans des onglets ou des requ√™tes AJAX (utilisez `requests` ou `selenium` si n√©cessaire).
- Utilisez `pandas.DataFrame` pour structurer les donn√©es.
- Exportez les donn√©es finales au format CSV ou Excel pour l'analyse.

---

## Liens utiles

- [Speedrun.com Super Mario Bros.](https://www.speedrun.com/smb1)
- [Documentation BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Documentation pandas](https://pandas.pydata.org/docs/)
- [Conditions d‚Äôutilisation Speedrun.com](https://www.speedrun.com/terms)

---

**Contact :** _AJEANEUDES_



# TODO:
# 1. Inspecter le HTML de chaque section du site cible.
# 2. √âcrire extract_leaderboards(soup): r√©cup√®re les records, joueurs, cat√©gories, etc.
# 3. √âcrire extract_guides(soup): r√©cup√®re les guides, auteurs, dates, liens.
# 4. √âcrire extract_resources(soup): idem pour ressources.
# 5. √âcrire extract_forums(soup): idem pour forums.
# 6. √âcrire extract_stats(soup): nombre de runs, followers, joueurs.
# 7. Structurer chaque extraction dans un DataFrame pandas.
# 8. Exporter chaque DataFrame en CSV ou Excel.
# 9. Tester/adapter la robustesse si le HTML √©volue ou si AJAX/API est utilis√©e.
# 10. Documenter l‚Äôusage du script.